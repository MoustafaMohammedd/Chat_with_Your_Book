Coursat.ai Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Coursat.ai Deployment of Deep Learning models Dr. Ahmad El Sallab Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai ML Cycle Coursat.ai Coursat.ai Pre-requisites ●Practical Machine Learning for Data Scientists ●Deep Learning for Computer Vision Coursat.ai Course contents Part 0: Deployment Scenarios Part 1: Client-side scenarios Part 2: Server-side scenarios Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Deployment scenarios Client Model compression Pruning Distillation Quantization Compression pipelines Optimized architectures Special conv types Efficient architectures Edge TFLite Rasperry Pi Mobile – TFLite Android Browser TFJS Server Cloud-based APIs TFHub Torchhub TF-API OBB Custom models Model serving Flask Django TFServing Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Deployment Scenarios Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Coursat.ai Module Roadmap Deployment pipeline Deployment constraints Deployment scenarios Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Deployment Pipeline Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Coursat.ai What we deploy? Data (x,y) Training Loop Model for e in epochs: for x_b, y_b in batches: - y_ = fwd(x) - e = loss(y,y_) - w’s = bwd(e) train(x,y) Coursat.ai What we deploy? Data (x,y) Training Loop Model train(x,y) Data prep - Load/Collect - Clean - “Analyse” optional → statistics (mean, var) - Transform (DA, Features Engineering, Features Derivation,...etc) Data prep is an IMPORTANT outcome of training It might also include some data stats, ex: mean, var → normalization Coursat.ai Data pipelines - ETL Data (RAM - Disk) Data pipeline x,y Model x Loss y y_ Optimizer Extract Transform Load Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai How we deploy? Model wrap-up Data (x) Fwd Model y_ = predict(x) → inference Data prep y_ y_ = fwd(x) Deployment Assets: - Data prep pipeline (+ stats if needed: batch norm) - Model Params + Architecture + Hyper params (if needed for inference) Coursat.ai Deployment Medium Where we deploy? Training Evaluation Inference Training Medium - Desktop: Corei 7,... - RAM: 12,32,64 GB,... - GPU: TitanX, 3080 Ti,... - Server→ Powerful (Corei 7, GPU, 64 GRAM,...) - Mobile → Some graphics accelerator - IoT device → Edge computing or cloud-server Coursat.ai Deployment Design Constraints Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Concerns of deployment 1- Compatibility - Same data prep pipeline → What’s done in training → repeat in testing! Data (x) Fwd Model Data prep y_ Deployment Assets: - Data prep pipeline (+ stats if needed: batch norm) - Model Params + Architecture + Hyper params (if needed for inference) Coursat.ai Concerns of deployment 1- Compatibility - Deployment HW compatibility: - Does the deployment HW has compute/graphics acceleration? GPU - Do we have the needed libraries to deal with the deployment HW? - Does the deployment HW support same programming language → Python - C/C++? Might not have GPU → ARM Might have other accelerators → OpenGL Might NOT be NVIDIA → Custom abstraction stack → OpenCL OR → provided by the HW vendor Might not support Python (Caffee, C/C++) Coursat.ai Concerns of deployment 2- Memory 3- Speed 4- Power consumption 5- Communication We never cared before! Even our dev process encourages large models! Coursat.ai Universal ML process “DL with Python and Keras, fchollet” Defining the problem and assembling a dataset Choosing a measure of success Deciding on an evaluation protocol Preparing your data Developing a model that does better than a baseline Scaling up: developing a model that overfits Regularizing your model and tuning your hyperparameters Coursat.ai Handling overfitting process “J. Howard, Fast.ai” Last thing! → Reduce model complexity (= reduce model size) We even cared to increase the model size Larger model size means: - Larger memory footprint - Longer inference (Conv 2 D, LSTM,...etc) - Higher compute = Higher power consumption Avg model size = 10^7 params We must reduce model size Coursat.ai Pre-trained networks might have huge memory footprint (Generalizable architectures) Very Deep Convolutional Networks for Large Scale Image Recognition. 16-19 layers Unfortunately, there are two major drawbacks with VGGNet: 1- It is painfully slow to train. (pre-train small and initialize larger) 2- The network architecture weights themselves are quite large (in terms of disk/bandwidth). Due to its depth and number of fully-connected nodes, VGG is over 533 MB for VGG 16 and 574 MB for VGG 19. This makes deploying VGG a tiresome task. Coursat.ai Pre-trained networks might have huge memory footprint (Generalizable architectures) NLP 2 wc 6 VPK 1 g.png GPT-3 = 700 GB on disk! Coursat.ai Which memory? - Training memory → Necessary for training only (batch_sz → GPU RAM) - Model size on desk → Necessary for inference → Needs: - High RAM → Run time memory loading - High desk space → Offline model saving Coursat.ai Deployment Scenarios Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Coursat.ai Deployment scenarios - Client - Server - Light-weight front-end → Only data preprocessing - Powerful server → GPU, Corei 7, 64 GB...etc - High latency → Round-trip decision path - Privacy → Data has to be uploaded to server Coursat.ai Deployment scenarios - Edge deployment - Mobile - Front-end processing → Mobile might have some accelerators, but no same as server - RAM is usually OK → Today’s mobiles, 6 GB - Low latency → Round-trip decision path - Privacy → Data on device Coursat.ai Deployment scenarios - Edge deployment - Embedded - Front-end processing → Very low resources, no graphics accelerators - Low power consumption → Powered on coin-cell battery - Could have no user-friendly OS → Micro-controller - ASIC: Could have no ‘know’ accelerators → Develop your own libs, in specific languages → C/C++, OpenCL,...etc → Could be provided by the vendor - Low latency → Round-trip decision path - Privacy → Data on device 9 df 4 b/static/f 1682 eef 7 da 7 e 8 d 989662 d 147 f 48977 c/7 fd 5 d/f 532739 a-171 e-4 aa 0- b 9 f 3-d 05 e 20710 b 69_raspberry-pi-4-model-b.jpg Rasperry Pi a.jpg Micro-controller Coursat.ai Part 1: Client Side Deployment Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Roadmap Module 1.1: Model compression Module 1.2: Edge Deployment Module 1.3: Mobile deployment Module 1.4: Browser deployment Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Model Compression Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Roadmap - Model compression techniques - Optimized architectures Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Levels of model optimization High level Low level Model level optimizations Hardware level translations HW independent HW dependent: GPU, CPU, TPU, FPGA, ASIC Mainly Python Could include other level languages: C/C++ No lib dependency CUDA: NVIDIA OpenCL/OpenGL: non NVIDIA Custom/Vendor specific: ASIC/FPGA/others Coursat.ai High level optimizations High level optimization Model compression Optimized Architectures - Architecture optimizations - Focus: runtime + memory - Could include one or more compression technique + other tricks - Could be available pre- trained - Examples: MobileNet, EfficientNet, ...etc - Focus on reducing number of params Coursat.ai Model compression Neural networks are “over-parametrized” by default → High redundancy “Make it work, then optimize” → Overfit then regularize Objective: Find minimum model topology (params), such that the performance is minimally affected /!\ There’s no “analytical” proof an architecture is minimal. So we go with Heuristics Coursat.ai Model compression techniques - Pruning - Knowledge Distillation - Quantization Coursat.ai Pruning Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Pruning - General from graph theory. Not specific to NNs - Pruning weights (synapses) - Remove specific connections - Pruning activations (neurons) - Remove the neuron + ALL connected synapses dJE_vHfGpPBtXLLXLmnBQ.png Pruning removes the pruned params unlike regularization But it has a regularization effect, so it might result in better performing model Coursat.ai Pruning is a form of regularization! In general, more parameters, means more complex model, means higher overfitting. Bigger model = Memory in the form of weights = Memorizing the training set. Avoids the model “memorizing” the training set. Coursat.ai General structure of Pruning Model Criteria evaluation Pruned model Re-training (Optional) Re-trained model Pruned weights are frozen, so that they do not obtain new values during re-training (if any) Any criteria MUST quantify the Importance of the weight somehow. Coursat.ai Pruning Criteria - Heuristics - Loss based We know the best criteria better have minimum impact on the loss: Remember: Objective of compression is: Reduce model size, without impacting performance Coursat.ai Brute-Force = First form of loss based for w_k in W: # O(W) w_k = 0 # Randomly set some weight # Evaluate loss for x,y in data: # O(M) y_ = fwd(x; W) #new W with w_k = 0, y_=WT.x → O(W) loss = eval(y, y_) Importance[w_k] = loss # prune least importance O(MW 2): M = #samples ~ 104 or 105 W = #params ~ 107 or 109 Coursat.ai Heuristics Criteria - Magnitude-based → Synapsis Pruning - Remove w_k with the smallest ||w_k|| first - Variance-based → Neurons Pruning - prunes neurons when the variance of the incoming weights are below some threshold 𝑇. i 1 2 3 j w_i w_j w_i = [w_i 1,w_i 2,w_i 3 ] → var_i w_j = [w_j 1,w_j 2,w_j 3 ] → var_j If var_j < T: w_j = [w_j 1,w_j 2,w_j 3 ] = [0, 0, 0] ALL based on assumptions (importance ∝magnitude or variance) Coursat.ai Loss based Criteria Any criteria MUST quantify the Importance of the weight somehow. Importance s_k = f(loss, w_k) - Sensitivity-based - Post-training - Gradient based - Importance s_k = grad_loss/grad_w_k - Penalty/Regularization based - Add L 1 or L 2 regularization term to the loss - During training - Encourage sparsity - Once trained, simply remove the small magnitude weights → Like magnitude based heuristics - Same as Ridge or Lasso → Already discussed Coursat.ai Optimal Brain Damage (LeCunn, 1989) - Inspired by Synapses death in Humans of-frontal-cortex-versus-age.png Coursat.ai Optimal Brain Damage (LeCunn, 1989) - SGD: - w(k+1) = w(k) - lr * grad(loss, w) - At the limit → grad(loss, w) = 0 → We cannot depend on the first derivative - Approximate the gradient of the loss as a tailor series - Use the second derivative → Hessian Neglect higher terms Coursat.ai Saliency Sk Coursat.ai Re-train or not to re-train? (c) compares the predictive performance with (lower) and without (upper) retraining after the pruning. It is very clear to see that retraining allows to eliminate as much as 70% of the parameters without a significant drop in predictive performance. Most of the time, pruning is followed by retraining the network to avoid severe deficits in accuracy. Both steps can be repeated iteratively until either the desired compression rate ℛis achieved, or ℒincreases drastically. Model Criteria evaluation Pruned model Re-training (Optional) Re-trained model Coursat.ai Distillation Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Knowledge Distillation (Caruana et al. 2008, Hinton et al, 2015) Train a complex “Teacher” model. yteacher= Teacher(x) (x, yteacher) = “Transfer” dataset Train a smaller “Student model” → tries to mimic Teacher model on the Transfer dataset. 8 Dw 14 Q.png Coursat.ai Dark Knowledge Analogous to “Dark Matter” in Physics (Hinton! Temprature, RBM, ….etc)(Neuroscientis) Naive way: logits = Teacher.predict(x) # logits = unnormalized probs yteacher= np.argmax(logits) Dark matter: Knowledge of the teacher is more in the relative probabilities of the wrong answers Coursat.ai Why training on labels is not a good idea? Labels hold one info: we should classify a dog But there are other info in the logits For example, a cow is 103 more likely than a boat. Cow, dog, cat are animals, while boat is an object. Boat is the least, so the model has some idea about the distinction between objects and animals. Training on the labels does not convey this info/knowledge to the student Train the student on the logits → L 2 Regression instead of CE loss Coursat.ai Quantization Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Weights Quantization 17 g.png Clustering (e.g. k-means) Centroids Weight sharing Code book + Quantization Index = Group index Original “value” is stored in 32-bits So code-book is 4 x 32 bits Index can be stored in 2 bits Coursat.ai Compression rate ℛ= #bits before quantization / #bits after quantization ℛ> 1, compression ℛ= 1, No compression ℛ< 1, Expansion b = #bits per weight W = number of weights k = number of centroids (rows in codebook) Let: W=9, b = 32 bits, k = 4 Before compression ⇒9 x 32 = 288 bits After compression: We have k possible indices Each is represented by 2 bits So we have 9 x 2 = 18 bits for the 9 weights Then, we need the codebook to translate back the centroid values, each represented by 32 bits = 4 x 32 So we have: 9 x 2 + 4 x 32 = 146 bits ℛ= 1.9 ~= 2 Compressed by 50% Coursat.ai Linear vs. Non-linear quantization _sampling.png Coursat.ai Huffman Encoding Optimal Pre-fix code ⇒Ensure no repetition Optimal Pre-fix code ⇒No code is prefix of another one. → Easier in decoding (we will see just a sequence of bits. Once a code is encountered, we immediately know it) Most frequent weights values/bins⇒ Shorter code ⇒Less number of bits Least frequent weights values/bins⇒ Longer code ⇒More number of bits 20-30% extra reduction in b (total number of bits for a network) example-of-histogram-of-the-neural-network-weights-after-the-first-training-iteration.ppm Coursat.ai Quantization aware training vs. Post training quantization Gholami, A., Kim, S., Dong, Z., Yao, Z., Mahoney, M.W. and Keutzer, K., A Survey of Quantization Methods for Efficient Neural Network Inference. In Low-Power Computer Vision (pp. 291-326). Chapman and Hall/CRC. Coursat.ai Quantization aware training QAT Gholami, A., Kim, S., Dong, Z., Yao, Z., Mahoney, M.W. and Keutzer, K., A Survey of Quantization Methods for Efficient Neural Network Inference. In Low-Power Computer Vision (pp. 291-326). Chapman and Hall/CRC. Note how the gradients are calculated wrt the full precision weights, not the quantized ones Coursat.ai Compression Pipelines Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Comparison of model compression techniques Pruning Distillation Quantization HW Dependency HW indep HW indep HW dep Model dependency DNN dep DNN indep DNN indep Coursat.ai Deep Compression (Han et al. 2015) 1- Pruning: Magnitude based → 9 x-13 x reduction 2- Quantization + Code-book re-training → 27 x-31 x reduction Having found the rough location of the centroids, Han et al. retrain the network to fine–tune the location of each centroid 3- Huffman Encoding → 35-49 x reduction Coursat.ai Deep Compression (Han et al. 2015) Polino, A., Pascanu, R. and Alistarh, D., 2018. Model compression via distillation and quantization. arXiv preprint arXiv:1802.05668. Coursat.ai Optimized Architectures Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai ConvNets everywhere since AlexNet, 2012 Coursat.ai Conv factorization Spatial/Point + Channel/Depth Coursat.ai Conv 2 D→ 4 D tensor n_in_maps x L x W x n_out_maps Coursat.ai Convolution dynamics: Coursat.ai Convolution dynamics Output 3 rd dim = number of kernels = nfeature_maps In TF: [filter_height=5, filter_width=5, in_channels=6, out_channels=12] Coursat.ai Factorized representation: Spatial/Point + Channel/Depth 4 u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1 c 7048 b 9618 d Coursat.ai Normal conv 9 J 9 tZmqEMOez 0 fI 2 ad 1 bg.png Spatial: locally connected Channel: fully connected (ALL input channels contribute to every output channel) W 5 x 3 Computational cost = HWK 2 NM #Params = K 2 NM Coursat.ai Special Conv Types Coursat.ai 1 x 1 conv Many usages: Modify #channels w/o messing the spatial dimension - Bottleneck: reduce #channels (ResNet) - Adjust #number of classes in Fully Conv models (SS: U-Net) Coursat.ai 1 x 1 conv representation: Point-Wise Spatial: no connectivity! Point-wise → No change in input dim Channel: Fully connected → Change the output dim Computational cost = HWNM #Params = NM (K=1) Coursat.ai Grouped Convolutions Grouped convolution is a variant of convolution where the channels of the input feature map are grouped and convolution is performed independently for each grouped channels. - Normal Conv: n_in x k x k x n_out → Every filter of the n_out can work in parallel → Channel level parallelization - Grouped conv → Model level parallelization → Create separate model for every bulk of input channels Coursat.ai Grouped Convolutions vs Normal Conv Coursat.ai Grouped Convolutions vs Normal Conv Normal: h x w x Din x Dout Grouped: if #groups=2, then h x w x Din/2 x Dout/2 → concat What we pay? We no longer extract features from ALL the Din channels at once (no kernel block is looking on all the input channels). But even this, could have regularization effect and reduce overfitting AlexNet was tested with and without GConv → With is better Coursat.ai Group conv representation Computational cost = G*(HWK 2 N/GM/G) = HWK 2 NM/G #Params = K 2 NM/G (1/G reduction) Spatial: local connectivity as normal Channel: group/local connectivity → less params/ops, but less interactions as well Coursat.ai 1 x 1 group conv Spatial: no connectivity! Point-wise → No change in input dim Channel: group/local connectivity → less params/ops, but less interactions as well Computational cost = HWNM/G #Params = NM/G (1/G reduction) Usage will become clear with ShuffleNet Coursat.ai Depth-wise conv = Special GroupConv Defined as a special case of grouped convolution where the numbers of input and output channels are same and G equals the number of channels. With #groups = Din = N, we have (Din/Din=1) feature map per group Coursat.ai Depth-wise representation Spatial: local connectivity as normal Channel: no connectivity (like 1 x 1 in spatial). Computational cost = HWK 2 N #Params = NK 2 (G=N=M) Usage will become clear with MobileNet Coursat.ai How to get different output channels (M ≠ N) with Depth-wise conv? Defined as a special case of grouped convolution where the numbers of input and output channels are same and G equals the number of channels. With #groups = Din = N, we have (Din/Din=1) feature map per group If we want different #out_channels (M=Dout), we can use group 1 x 1 conv with #groups = Din, we have (Dout/Din=M/N) output feature maps per group. Coursat.ai Depth-wise separable convolution First used in Xception: Deep Learning with Depthwise Separable Convolutions: 1- Channel/Depth wise conv: spatial conv per input channel 2- Point-wise conv: 1 x 1 conv over spatial maps * N N=G=3 GConv (G=N) = DWise + 1 x 1 GConv M/N=6/3=2 M=6 Coursat.ai Depth-wise separable convolution 1- Depth/Channel wise conv 6 z 6 ESzsRW-9 q 5 F_neOsg.png Coursat.ai Depth-wise separable convolution 2- Point-wise conv 7 a 20 gyuunpJzXGnWayUDQ.png x 256 Coursat.ai Depthwise separable conv = Depth-wise + 1 x 1 conv Computational cost = HWK 2 N #Params = NK 2 (G=N=M) Computational cost = HWNM #Params = NM (K=1) Computational cost = HWK 2 N + HWNM #Params = NK 2 + NM Coursat.ai Let’s understand it with Dense layers first W 5 x 3 W 5 x 1 W 1 x 3 + Coursat.ai What we pay? - Normal conv: for each output filter n_in x k x k, create an output feature map. We have n_out of those. - So we have n_out x n_in x k x k, parameters and operations. - But we have independent n_out feature maps, created from full convolution for separate kernels over all the input channels - Depth-wise: first creates n_in feature maps, using (n_in x k x k) kernels, then “scales” those into n_out feature maps, using (n_out x 1 x 1 x n_in) kernels. - We have n_in x k x k + n_out x 1 x 1 x n_in parameters and operations - But the point-wise operation is not extracting any spatial features, it is just a scaling/weighting of the already extracted spatial features - The reduced number of parameters might cause underfitting Coursat.ai Efficient Architectures Coursat.ai Group Conv in AlexNet Coursat.ai Grouped Convolutions in AlexNet, 2012 First introduced in AlexNet (1.5 GRAM GPU): - Normal Conv: n_in x k x k x n_out → Every filter of the n_out can work in parallel VcuKKX 1 TCKMA.png Coursat.ai ConDenseNet Coursat.ai CondenseNet, 2018 Inspired by DenseNet: - Features maps are affected by learnable connectivity from previous layers Coursat.ai CondenseNet, 2018 Coursat.ai CondenseNet performance Coursat.ai ResNet and ResNeXT “Bottleneck” Coursat.ai Bottleneck ResNet (2014) Skip connection 6 dXaYbqkEYQ.png Skip connection requires the input and skip features maps to be the same. Coursat.ai ResNext → 1 x 1 GConv Gconv reduces the cost by 1/G, at the expense of less channel interaction. So do 1 x 1 to reduce conv cost, then gconv then 1 x 1 to have more channel interaction Coursat.ai Inception in GoogLeNet Coursat.ai 1 x 1 Conv bottleneck: GoogLeNet (2014): Going Deeper with Convolutions “The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant”, GoogLeNet paper Inception module: reduce #input channels = reduce number of filters. While compression was not the main goal, but the same idea will inspire other architectures for compression Coursat.ai Conv Encoder: Close the semantic gap Encoder 448 x 448 7 x 7 Semantics, Receptive fields Feature map size +More features per receptive field We want smaller features maps, but many of them (channels) to have more features per receptive field. For inception, this is very costly, as we have more than one covn block per input Coursat.ai Bottleneck ResNet (2014) 6 dXaYbqkEYQ.png For extra inceptions, use 1 x 1 bottleneck! This will reduce the channels, and computations, but keep the same features maps. Notice how we have: - 1 x 1 bottleneck - True 1 x 1 for pixel scale features. Coursat.ai SqueezeNet Coursat.ai SqueezeNet, 2016 SqueezeNet: AlexNet-level accuracy with 50 x fewer parameters and <0.5 MB model size Tricks: Strategy 1. Replace 3 x 3 filters (in AlexNet) with 1 x 1 filters. Given a budget of a certain number of convolution filters, we will choose to make the majority of these filters 1 x 1, since a 1 x 1 filter has 9 X fewer parameters than a 3 x 3 filter. Strategy 2. Decrease the number of input channels to 3 x 3 filters. Bottleneck strategy similar to inception module in Googlenet: Architecture.png Coursat.ai Fire module squeeze layers to decrease the number of input channels seen by 3 x 3 filters Coursat.ai SqueezeNet Strategy 3. Downsample late in the network so that convolution layers have large activation maps. This is a famous trick. For any encoder, as we go deeper, we downsample the image (MaxPool, Stride,..etc), why?: 1- Reduce the size of feature maps at the deep layers → Less flatten size and less parameters for the classification part 2- Increase the receptive field w.r.t. input Encoder 448 x 448 7 x 7 Semantics, Receptive fields Feature map size Coursat.ai Closing the semantic gap on a limited parameters budget With reduced number of params with strategy 1 and 2, we don’t have enough spatial features extracted (1 x 1 conv summarized and compressed them). It is not wise to “aggressively” compress the feature maps. If early layers in the network have large strides, then most layers will have small activation maps. Conversely, if most layers in the network have a stride of 1, and the strides greater than 1 are concentrated toward the end of the network, then many layers in the network will have large activation maps. “Strategies 1 and 2 are about judiciously decreasing the quantity of parameters in a CNN while attempting to preserve accuracy. Strategy 3 is about maximizing accuracy on a limited budget of parameters.”, squeezenet paper Coursat.ai Residual connections (bypass) Skip connections: - Vanishing gradients → Faster conversion - Recover loss of features due to compression But this has a limitation: Since we add the output to the input (skip), the number of channels must be the same! Coursat.ai SqueezeDet ConvDet→ based on SqueezeNet backend “Inspired by YOLO [21], we adopt a single- stage detection pipeline: region proposition and classification is performed by one single network simultaneously”, SqueezeDet Coursat.ai MobileNet v 1 Depswise Separable Conv Coursat.ai Depthwise separable conv = Depth-wise + 1 x 1 conv Computational cost = HWK 2 N #Params = NK 2 (G=N=M) Computational cost = HWNM #Params = NM (K=1) Computational cost = HWK 2 N + HWNM #Params = NK 2 + NM Coursat.ai Normal conv 9 J 9 tZmqEMOez 0 fI 2 ad 1 bg.png Spatial: locally connected Channel: fully connected (ALL input channels contribute to every output channel) W 5 x 3 Computational cost = HWK 2 NM #Params = K 2 NM Coursat.ai MobileNet v 1 (Google, 2017) MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications 8 cvrs 7 gnTDf 6 acRvDw.png?q=20 M: Number of input channels, N: Number of output channels, DK: Kernel size, and DF: Feature map size. #operations reduction: (DWise/Standard) Coursat.ai MobileNet v 1 Width Multiplier α for Thinner Models: Width Multiplier α is introduced to control the input width of a layer, which makes M become αM. And the depthwise separable convolution cost become: Accuracy drops off smoothly from α=1 to 0.5 until α=0.25 which is too small. Coursat.ai MobileNet v 1 Resolution Multiplier ρ for Reduced Representation: Resolution Multiplier ρ is introduced to control the input image resolution of the network, with Resolution Multiplier ρ, the cost become: Accuracy drops off smoothly across resolution from 224 to 128. We apply this to the input image and the internal epresentation of every layer is subsequently reduced by the same multiplier. In practice we implicitly set ρ by setting the input resolution. Coursat.ai MobileNet v 1 ImageNet classification results Coursat.ai MobileNet v 1 Object detection MS-COCO MobileNet is just a backend! It can work with single and 2-stage detectors (Faster RCNN and SSD), for different input resolution (300 m 600). Coursat.ai Pros and Cons of DWise Sep Conv Pros: - Efficiency in #ops and #params Cons: - Less #params is less capacity No channels interaction - Cost is transferred to 1 x 1 conv → HWNM Coursat.ai ShuffleNet Group Conv Coursat.ai ShuffleNet, 2017 If we want to increase channel level interaction between groups, we can shuffle feature maps. “ In tiny networks, expensive pointwise convolutions result in limited number of channels to meet the complexity constraint, which might significantly damage the accuracy.”, ShuffleNet 1 Kxs 9 hQ 76 tDDW.png Coursat.ai Channel shuffle With GConv, no inter-group connections → Shuffle Channel/Depth wise Coursat.ai ResNext → 1 x 1 GConv Gconv reduces the cost by 1/G, at the expense of less channel interaction. So do 1 x 1 to reduce conv cost, then gconv then 1 x 1 to have more channel interaction Coursat.ai ShuffleNet = 1 x 1 GConv + Channel shuffle 5 ck 2 kfyfzO 2 pIQ.png Coursat.ai ShuffleNet, 2017 1 x 1 GCov + Shuffle + DWise + Skip ShuffleNet Unit: - 1 x 1 GConv: split the input channels into groups - Suffle - DWConv → Reduce computations per group - Last 1 x 1 GConv → Adjust the number of channels to be added with the skip Coursat.ai ShuffleNet vs MobileNet v 1 Coursat.ai MobileNet v 2 Coursat.ai MobileNet v 2, Inverted Residuals and Linear Bottlenecks, Google 2018 8 UvZJWNW 4 E/WsKk-tbzp 8 I/AAAAAAAAChw/OqxBVPbDygMIQWGug 4 ZnHNDvuyK 5 FBMcQCLcBGAs/s 640/image 5.png Also to solve the transferred cost to 1 x 1 Conv: But without 1 x 1 GConv However, we could reduce the Channel/Depth dimension, and expand only when needed Coursat.ai Bottleneck Connections Normal skip (ResNet) + Bottleneck Efficient, but expanding through the depth of the network → Increasing number of output channels Why not expanding when we need only? 6 dXaYbqkEYQ.png Coursat.ai Inverted Bottleneck Connections Why not expanding when we need only? Keep channels compressed all the time Expand with 1 x 1, then perform Dwise Sep conv using inverted bottleneck. This will help making normal residual keeping the same input and output channels. Since Dwise Sep Conv is already low cost, we can work on many channels. 3 U 0 V 3 VHBV 2 olpzC 3 mGsJQ.png Coursat.ai Inverted Residual Block Coursat.ai MobileNet v 2, Inverted Residuals and Linear Bottlenecks, Google 2018 Coursat.ai Optimized architectures vs. Special Conv types Cheat Sheet Coursat.ai Optimized architectures cheat sheet Coursat.ai Neural Architecture Search (NAS) “Searching for MobileNetV 3“ Coursat.ai NAS, GoogleBrain ● In this paper, we study a method to learn the model architectures directly on the dataset of interest. ● As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. ● In our experiments, we search for the best convolutional layer (or “cell”) on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, which we name a “NASNet architecture” 8 D 14 Y 0-IsRL 7 aKVljLpg.png Coursat.ai NAS, GoogleBrain ● In our approach, the overall architectures of the convolutional nets are manually predetermined. ● They are composed of convolutional cells repeated many times where each convolutional cell has the same architecture, but different weights. ● To easily build scalable architectures for images of any size, we need two types of convolutional cells to serve two main functions when taking in a feature map as input: (1) convolutional cells that return a feature map of the same dimension, and (2) convolutional cells that return a feature map where the feature map height and width is reduced by a factor of two. 8 D 14 Y 0-IsRL 7 aKVljLpg.png Coursat.ai NAS, GoogleBrain blocks or cells are not predefined by authors. Instead, they are searched by reinforcement learning search method. ● Normal Cell: Convolutional cells that return a feature map of the same dimension. ● Reduction Cell: Convolutional cells that return a feature map where the feature map height and width is reduced by a factor of two. ● Only the structures of (or within) the Normal and Reduction Cells are searched by the controller RNN (Recurrent Neural Network) 8 D 14 Y 0-IsRL 7 aKVljLpg.png Coursat.ai Searching with RNN architecture generator + RL Neural Architecture Search with Reinforcement Learning, 2016 → Uses REINFORCE NASNet, 2018 → Uses PPO Form of Meta-learning: learning to learn Coursat.ai RNN Controller The gradient is scaled by the validation accuracy of the child network to update the controller RNN such that the controller assigns low probabilities for bad child networks and high probabilities for good child networks. Coursat.ai NAS, GoogleBrain Search directly on CIFAR-10 → 2.4% → SoTA Transfer to ImageNet (and re-train, but not search) → 82.7% top-1 and 96.2% top-5 → - 1.2% better in top-1 accuracy than the best human-invented architectures while - having 9 billion fewer FLOPS – a reduction of 28% in computational demand from the previous state-of-the-art model Coursat.ai RNN Controller This structure enables inception modules as we will see: 8 zo 6 ZTEDng.png Coursat.ai Train for 4 days on 500 GPUs!! Coursat.ai NASNet-A uB 72 g 9 ixLvnSJxNW 2 f 1 ng.png Coursat.ai Convention NASNet-A N = 6 cell repetetions #filter = 768 per cell Coursat.ai NASNet-B x-IG 3 nKFTTfJPMFCubhg.png Coursat.ai NASNet-C KYr 5 nloF 1-fXbXfYy 7 wQ.png Coursat.ai Results - CIFAR-10 8 dHm 56 KIw.png Coursat.ai Results - ImageNet 59 AFsvlYg.png Coursat.ai Results - ImageNet WFJ 5 QHdbrUU 2 hHlejs 4_A.png Coursat.ai Results - Object Detection MS COCOO cL 6 b-i 0 D 0 LSYwjM 7 l 28 wQ.png 5 Wg 5 icHcteVhTR 7 IefRw.png Coursat.ai AutoML Google AutoML: based on NAS: Google AutoML AutoKeras MS AutoML, based on another approach Azure AutoML ALL are variants of Meta- learning: learning to learn Coursat.ai MobileNet v 3 Coursat.ai Searching for MobileNet v 3 MobileNetV 3 is tuned to mobile phone CPUs through a combination of hardware aware network architecture search (NAS) complemented by the NetAdapt algorithm and then subsequently improved through novel architecture advances. This paper starts the exploration of how automated search algorithms and network design can work together to harness complementary approaches improving the overall state of the art MobileNetV 3-Large and MobileNetV 3-Small Coursat.ai Efficient Mobile Building Blocks MobileNetV 1 → depthwise separable convolutions MobileNetV 2 → linear bottleneck and inverted residual structure ⇒Use as bulding blocks for NAS → Let the search specify the internal structure → Repeated Nx Coursat.ai EfficientNet Coursat.ai EfficientNet, Google AI Convolutional neural networks (ConvNets) are commonly developed at a fixed resource cost, and then scaled up in order to achieve better accuracy when more resources are made available. Ex: ResNet-18 to ResNet-200 by increasing the number of layers The conventional practice for model scaling is to arbitrarily increase the CNN: - depth or - width, or - to use larger input image resolution for training and evaluation We need principled method to scale up a CNN to obtain better accuracy and efficiency Coursat.ai EfficientNet, Google AI Develop a baseline with AutoML → Scale-up systematically Coursat.ai Compound Scaling The first step in the compound scaling method is to perform a grid search to find the relationship between different scaling dimensions of the baseline network under a fixed resource constraint (e.g., 2 x more FLOPS). This determines the appropriate scaling coefficient for each of the dimensions mentioned above. We then apply those coefficients to scale up the baseline network to the desired target model size or computational budget. This compound scaling method consistently improves model accuracy and efficiency for scaling up existing models such as MobileNet (+1.4% imagenet accuracy), and ResNet (+0.7%), compared to conventional scaling methods. Coursat.ai Compound scaling - up → Principled way Coursat.ai Baseline ⇒EfficientNet(s) Coursat.ai EfficientNet(s) Results 8 ko/XO 3 BtHnUx 0 I/AAAAAAAAEKk/rJ 2 tHovGkzsyZnCbwVad-Q 3 ZBnwQmCFsgCEwYBhgL/s 640/image 3.png Coursat.ai Edge Deployment Tools Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Roadmap TFLite overview Edge deployment – TFLite Rasperry Pi Mobile deployment – TFLite Android Browser deployment - TFJS Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai TFLite Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Why DL frameworks? HW Abstraction - Code = HW Agnostic (HW Platform Agnostic) - DL framework (TF, Pytorch,...etc)→ Architecture aware Compiler = Translation → Binary Without frameworks, you would write tons of codes just to do Matrix Multiplications Coursat.ai Deployment scenarios - Edge deployment - Mobile - Front-end processing → Mobile might have some accelerators, but no same as server - RAM is usually OK → Today’s mobiles, 6 GB - Low latency → Round-trip decision path - Privacy → Data on device Coursat.ai Deployment scenarios - Edge deployment - Embedded - Front-end processing → Very low resources, no graphics accelerators - Low power consumption → Powered on coin-cell battery - Could have no user-friendly OS → Micro- controller - ASIC: Could have no ‘know’ accelerators → Develop your own libs, in specific languages → C/C++, OpenCL,...etc → Could be provided by the vendor - Low latency → Round-trip decision path - Privacy → Data on device 9 df 4 b/static/f 1682 eef 7 da 7 e 8 d 989662 d 147 f 48977 c/7 fd 5 d/f 532739 a-171 e-4 aa 0- b 9 f 3-d 05 e 20710 b 69_raspberry-pi-4-model-b.jpg Rasperry Pi a.jpg Micro-controller Coursat.ai Deployment scenarios - Client - Server - Light-weight front-end → Only data preprocessing - Powerful server → GPU, Corei 7, 64 GB...etc - High latency → Round-trip decision path - Privacy → Data has to be uploaded to server Coursat.ai Levels of optimizations High level Low level Network compression - Pruning - Distillation - Quantization Efficient Architectures - MobileNet - SqueezeNet - EffcientNet GPU - CUDA - OpenGL - OpenCL CPU - ArmNN - Intel FPGA ASIC HW Agnostic HW Dependent /Aware OS: Android/iOS Linux (+Raspian) Windows Coursat.ai TFLite High level Low level Network compression - Pruning - Distillation - Quantization Efficient Architectures - MobileNet - SqueezeNet - EffcientNet GPU - CUDA - OpenGL - OpenCL CPU - ArmNN - Intel FPGA ASIC HW Agnostic (Mainly SW) HW Dependent /Aware Quantization mainly → Highest compression Recently pruning Mostly Low level → GPU, CPU=Intel+Arm OS: Android/iOS Linux (+Raspian) Windows Coursat.ai TFLite Coursat.ai TFLite High level Low level Network compression - Pruning - Distillation - Quantization Efficient Architectures - MobileNet - SqueezeNet - EffcientNet GPU - CUDA - OpenGL - OpenCL CPU - ArmNN - Intel FPGA ASIC Converter Training side Interpreter Device side OS: Android/iOS Linux (+Raspian) Windows Coursat.ai TFLite process Coursat.ai TFLite Coursat.ai HW Accelerators Coursat.ai What if model is in keras format? Coursat.ai How to save/load model? - Keras model → .hdf 5 - When you load the model, you need to first build it, then load its weights - So you need access to the building code - TF SavedModel - Holds MetaGraph data - So no need to “know” the model code in = Input(..) out = Conv 2 D(...)(in) model = Model(in, out) model = load_model(model_file) export_dir = 'saved_model/1' tf.saved_model.save(model,export_dir) in = Input(..) out = Conv 2 D(...)(in) model = Model(in, out) model.compile(..) model.fit(..) model.save(model_file) loaded = tf.saved_model.load(export_dir) Coursat.ai Keras model + MobileNet pre-trained example Coursat.ai How to convert model? converter = tf.lite.TFLiteConverter.from_saved_model(export_dir) tflite_model = converter.convert() tflite_model_file = pathlib.Path('model.tflite') tflite_model_file.write_bytes(tflite_model) Coursat.ai Command line interface If we don’t know what the model code looks like, but we have the model file Coursat.ai TFLite inference process Coursat.ai How to interpret/load the model? Load tflite model Cast the input and output shapes Feed data, with the expected shape Invoke Get the output with the expected shape Coursat.ai Optimization options Default: balance latency and space. You can specify instead: Coursat.ai Quantization in TFLite Post training quantization → To quantize, we need the dynamic range (we can live without by assuming certain max and min) → But we don’t know that since we have an already trained model Coursat.ai Quantization in TFLite - Representative Data Coursat.ai INT 8 Quantization Some devices might not have float Some operations might not be supported! → Error raised Coursat.ai TFSelect Some operations might not be supported! → Error raised →Constraint the supported ops from the begnning to be used Coursat.ai TFLite + Rasperry Pi Coursat.ai Rasperry Pi Coursat.ai Rasperry Pi Can be powered with Powerbank Coursat.ai Rasperry Pi Coursat.ai Rasperry Pi Coursat.ai Bringing-up Coursat.ai Bringing-up - Linux-based distributions - Rasbian - Ubuntu - Desktop vs. Headless mode Coursat.ai Rasbian OS Follow official instructions here Always use the official imager Once done, you have a ready SD card to plug in the Pi. + Rasbian has a full desktop interface, so you will find it booting once connected. + Easy config using raspi-config tool - Heavy due to desktop graphics - Some recent tools/packages are not easy as Ubuntu sudo snap install rpi-imager Coursat.ai Remote connection Imagine you write your control script in Python, who will run it? No monitor! You have two options: 1- SSH: CLI control A- Enable SSH using sudo raspi-config → Interfacing options→ SSH → Enable, see here B- You can get the Pi IP using ifconfig with a monitor connection, then 2- VNC: Follow instructions here. This option is only possible for Desktop OS (not possible for Ubuntu). ssh Pi’s IP address> Coursat.ai Ubuntu 20.04 Recently supporting Pi Follow instructions here + Light weight + All Ubuntu supported packages - No desktop < Pi 4 (can be done, but not straightforward) - No raspi-config tool (yet) sudo snap install rpi-imager Coursat.ai Headless setup In server/headless setups, you don’t have Monitor connected to the Pi→ How to communicate? - We can ssh, and control via CLI. - For LAN you just connect the cable. - For WiFi, how to connect in case of secured networks? Follow instructions here. - Basically, you edit the network-config.txt file in system-boot, to add the desired WiFi to connect. This is done on the SD card. - But how to know the IP? wifis: wlan 0: dhcp 4: true optional: true access-points: <wifi network name>: password: "<wifi password>"v Coursat.ai Headless setup - But how to know the IP? After the Pi connects to WiFi: - Use any WiFi monitoring App (“Who is using MyWiFi?” Apps). You will find the Pi connected with name “ubuntu”. - If using a mobile hotspot→ you can get it from the connected devices IP’s. - Alternative: On Ubuntu, find the Pi by MAC address: arp -na | grep -i "b 8:27:eb" will give you the IP Coursat.ai Remote SSH Once you have the IP, you can ssh the Pi. User name is just ubuntu. First access will ask you to setup a password: ssh Pi’s IP address> This is needed in both headless/server or desktop setups, because even in desktop, imagine you write your control script in Python, who will run it? No monitor! SSH is enabled by default. In some cases, you might need to manually enable it, follow the instructions here. Coursat.ai Still not connected to the internet? Sometimes the structure of the network-config file that you modified before boot gets messed up when you boot. This would cause your Pi not to be able to connect to your wifi. To fix this you need to go into the correct file and correct the issue. Run: sudo nano /etc/netplan/50-cloud-init.yaml so you can edit the file. Edit it so it looks like this again, the indentation needs to be correct for the .yaml to work: wifis: wlan 0: dhcp 4: true optional: true access-points: "home network": password: "123456789" Save and exit the file with Ctrl + S and Ctrl + X. Coursat.ai Dev Env Coursat.ai Dev Env - VS Code - MobaXterm - SnowFlakes Coursat.ai VS Code remote VS Code is an easy way to develop in remote machines. The other option is to have two tools: 1) SSH to send CLI commands 2) FTP to handle files. This is hard! It gives even luxury if running, and setting breakpoints on the remote machine. To do on Pi follow instructions here. Same procedure works for ANY remote SSH server (Cloud/AWS or local). You will need to setup first Remote SSH in VS Code Coursat.ai VS Code remote 1. Press Remote explorer 2. Add server/Pi IP. Will ask for ssh IP 3. Add folder to open. Might ask for pass again. You can edit the hosts in the config file (useful if number of IPs get large) Coursat.ai VS Code remote Terminal IP denotes it’s connected Choose which python (anaconda? env?) to use Execute terminal commands Coursat.ai SSH+FTP MobaXterm Windows Snowflakes Ubuntu Coursat.ai Same process of deployment with TFLite Coursat.ai You just need the interpreter at the device! Coursat.ai Image classification 1 2 3 4 Coursat.ai Image classification Coursat.ai Object Detection main.py Coursat.ai Object Detection detector.py 1 2 3 4 Coursat.ai Accelerators - Movidius Coursat.ai USB Compute accelerators to 5 google.com/wp-content/uploads/sites/4/2019/03/google-coral-ai-iot-products.jpg?quality=82&strip=all 607/blog_statics/a 94 a 3 bcca 6 d 3 f 24 d 1 bace 00 ad 3749 da 389 ea 53 e 1/images/ncs/ keras-ncs.png Coursat.ai Custom TF model 1- Model → TF SavedModel 2- SavedModel → IR (Intermediate representaiton) 3- Use IENetwork class to load the model graph and binary Coursat.ai OpenVINO Coursat.ai Demo Object detection Coursat.ai Mobile Deployment Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Android Development Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Structure of Kotlin Android App • Kotlin is a Java-like language, which is widely used for Android development, great intro is here • You need Android Studio • Great tutorial to start is here • Main takeaways: • The main entry point is an activity • Activity needs a unique package name • You need to set the Min SDK to support wider device types Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Project structure • Activity is created as per the info in project creation. • Frontend: • activity_main.xml • Backend: • Activity inherits from AppCompatActivity • Overrides different events. Min is onCreate. Other possible events: onClick,…etc. • Loads the frontend: setContentView Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai TFLite in Android App Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai App architecture Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai How to feed input and get output of the trained model? Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Image Classification Android App Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Project structure (Source is here) • view/ImageClassifierActivity.kt: • Main App activity and results (step 4) • Tflite/Classifier.kt: • model handler (steps 1 –4) • Assets: all model files (tflite model). • Handled using AssetManager class. • res/activity_image_classifier.xml: • frontend • Gradle scripts: • build flags and instructions Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Front end • Static images • Pre-loaded • If clicked: trigger the classifier • Produce Toast msg with the class Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Main activity • Loads front end • Register onClick listener classbacks on the static images • Calls the classifier and get result • Toast msg with the class Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Classifier 1. Initialize the interpreter • Interpreter options (can be left as defaults) • Use assetManager (from the main activity) to open file descriptor (openFd) • Convert into FileStream • Set file offset and length • Load the mode using .map on the fileChannel • Now the interpreter can be loaded using the returned model file and options from loadModelFile Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Classifier 2. Prepare the input • Scale image as expected by the model • Convert from ARGB 2 RGB: • 32 bit: A-R-G-B • Ignore left byte (A: transparency) • R = input.shr(16) & 0 xFF 🡪 Get the 3 rd byte and mask • G = input.shr(8) & 0 xFF 🡪 Get the 2 nd byte and mask • B = input. & 0 xFF 🡪Get the 1 st byte and mask Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Classifier 3. Perform inference • Use the interpreter and pass the processed image • The result is an array of the same size as the labels • Labellist is loaded from the assets label.txt 4. Get the output result, which is an output var • Sort the result by confidence/probability. In the main activity we pick the top one (result.get(0)) Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Image Classification Android App From Camera Feed using MobileNet Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Same steps as before (Source is here) • Same Classifier class • New activity=CameraActivity as now we don’t have static images Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Camera feed Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Process input: YUV 2 RGB Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Capture image and feed to the classifier Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Object Detection Android App From Camera Feed Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Same steps as before (Source is here) • Same Classifier class • Same CameraActivity • Steps 3 requires special handling for multiple objects detection and special output format Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Multiple objects detection • Frame processing • Results parsing Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Object detection class Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Browser Deployment Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai TFJS Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai TFJS Architecture Copyright© 2022 by Coursat.ai. All rights reserved. On Device: Generic WebGL On Server/Device: Requires installation of TF GPU drivers Coursat.ai How JS runs? • It can run directly in the browser. • How TF and other python libraires are installed? Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Simple TFJS model Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Simple TFJS model Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Iris data classifier • Running as html without Node.js will result in error • F 12console • Iris.csv is Not in the file system • JS will looks on the “server” file system (using • So scripts need a webserver to run = Node.JS • This can be done in many IDEs, like Brackets • Now data is relative to the page directory Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Tell TFJS which column is the label in the CSV Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Convert string labels to OHE • trainingData is dict • map works per row • Labels is OHE of 3 values, each 1 if the species column matches the name, else it’s 0. Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Run in bricks.io IDE Copyright© 2022 by Coursat.ai. All rights reserved. Run from here Coursat.ai Run in Chrome with Webserver • Install Web Server for Chrome App • Launch the server: chrome://apps and click the icon • Choose folder • Click on the web server url and choose the html to run Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai MNIST Hello World • Canvas + img to draw • Buttons • Data.js: to load data • Script.js: The model Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Data.js: Sprite sheet Copyright© 2022 by Coursat.ai. All rights reserved. All data is concatenated in one image: builder/mnist_images.png Loading in JS file by file is very slow. So we put all in one image and slice it. In game development, this is called a Sprite (game assets). Coursat.ai Data.js: Binary labels Copyright© 2022 by Coursat.ai. All rights reserved. Labels in one binary: data/model-builder/mnist_labels_uint 8 10 bits per label. Needs a hex viewer. Easy for OHE. Coursat.ai Script.js Copyright© 2022 by Coursat.ai. All rights reserved. • Tf.tidy cleans RAM after each batch. Coursat.ai Train by running in Node.js or Webapp server in chrome Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai After training is done Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Summary • Client/Device side deployment scenarios • Edge deployment requirements and constraints • Model compression techniques • Optimized architectures and special conv types • TFLite (+Pi, +Mobile) • TFJS Coursat.ai Part 2: Server Side Deployment Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Where the model comes from? • Black box: • TF-API • TFHub and Torchhub • Whitebox: • Fine-tune • TF-API • Scratch • Yolov 5 Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Roadmap Model options – Cloud-based vs Custom Model Serving – Flask, Django EC 2, TFServing Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Cloud based APIs Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai TFHub and Torchhub Keras and Torchvision local models: Classification Object Detection Semantic Segmentation TFHub model: TFHub object detection TFHub image classification Coursat.ai Classification Coursat.ai Object Detection 306 Coursat.ai Semantic Segmentation Coursat.ai TFHub object detection 308 TFHub models Coursat.ai TFHub object detection 309 Coursat.ai TF-API OBB use case Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai What is TF OBB API? • Set of tools + models (Model Zoo) for Object Detection • When?: • Blackbox model (same as TFHub) • Whitebox: Transfer learning fine tuning scenario. But cannot modify in model architecture like model from scratch (e.g. YOLO). • This is important when you have your own classes, not part of any existing model. In this case, TFHub scenario cannot work. • Also, if you have very custom and different dataset, you might need to fine tune. • Tutorial • How to install • Steps to query TF-API • Steps to fine tune on custom data Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Basic installation steps • Steps can be found here • Example of installation on Colab (also works local) is here Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Get predictions from pre-trained model Copyright© 2022 by Coursat.ai. All rights reserved. More models on Model Zoo A full list of the labels files included in the TensorFlow Models Garden can be found here Coursat.ai Get predictions from pre-trained model Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Get predictions from pre-trained model Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Fine tune on Custom Dataset: Masks detection Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Fine tune on Custom Dataset: Masks detection Copyright© 2022 by Coursat.ai. All rights reserved. • For custom data, we need to annotate some images of our own. • First, we collect data, with images of each class in a folder with that class name. Here’s a script to do that using the web cam, script • Next, you need to annotate the images (bounding box) using labelImg on your local PC. • If you work on colab, you need to upload those after you annotate on local PC. Coursat.ai TFRecords • Loading image by image: slow and repeated pipeline. • Loading all in ram: need a lot of memory. • Tfrecords: saves the data in “batches” of processed numpy like format. • TF-API uses TFRecords. We need to convert the annotated images into tfrecords using the generate_tfrecord.py • Tfrecord: we need to convert images into numpy. Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Fine tune on Custom Dataset: Masks detection Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Fine tune on Custom Dataset: Masks detection Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Fine tune on Custom Dataset: Masks detection Copyright© 2022 by Coursat.ai. All rights reserved. python TensorFlow/models/research/object_detection/model_main_tf 2.py --model_dir=TensorFlow/workspace/models/my_ssd_mobnet --pipeline_config_path=TensorFlow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=5000 Coursat.ai Run inference on the new model checkpoint Coursat.ai YOLOv 5 vs. DETR OBB Use Case Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Why and When? • Some model architectures are NOT in models zoo “yet” • Also, we might to change, or invent (in research) new models. • In such cases, we need to train our models from scratch Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Pre-trained YOLO v 5 vs DETR Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Pre-trained YOLO v 5 vs DETR • We can find some comparisons between both models on their official repos, in terms of mAP, model size and inference time. See YOLO v 5 vs DETR. The numbers on COCO suggest better performance of YOLO v 5 over DETR: • mAP: DETR (42-44), while YOLO v 5 (37-52). • Model size: DETR (159 M-232 M), while YOLO v 5 (7.3 M-87.7 M). • Inference time: DETR (36 ms-50 ms), while YOLO v 5 (2.2 ms to 24.9 ms). Comparison here might not be fair, since YOLO v 5 is reported in V 100 GPU, while it is not clear for DETR. Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Pre-trained YOLO v 5 Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Pre-trained DETR Copyright© 2022 by Coursat.ai. All rights reserved. Create DETR class as in here following DETR architecture: Load model checkpoint for MS COCO: Notice how we needed to define new architecture not in model zoo Coursat.ai Pre-trained YOLO v 5 vs DETR Copyright© 2022 by Coursat.ai. All rights reserved. YOLOv 5 DETR Coursat.ai San Francisco Street Sign Detection Normal traffic signs are standard Copyright© 2022 by Coursat.ai. All rights reserved. We will use the San Francisco Parking Signs Dataset Coursat.ai Weights and Biases • Introduction • Used for experiments tracking Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai YOLOv 5 fine tune on SF data Copyright© 2022 by Coursat.ai. All rights reserved. In this part, we want to fine-tune the pre-trained YOLO v 5 on SF Dataset. We follow this example. This requires to prepare sf.yaml file as indicated. Coursat.ai BBOX formats Copyright© 2022 by Coursat.ai. All rights reserved. The SF Dataset follows the PASCAL VOC format of bbox (xmin, ymin, xmax, ymax). However the YOLO format is (x_center, y_center, width, height). So we have to make this transformation when writing the sf.yaml file. For full details about bbox formats check this link. Coursat.ai BBOX formats Copyright© 2022 by Coursat.ai. All rights reserved. According to this tutorial we need: 1.Create new file under {data_dir}/labels/image.iloc[0]["image_name"] 2.For each box entry in image, create a row: 0={fake class name as we dont have except one class} x_center, y_center, width, height But we have x_min, x_max, y_min, y_max We need to transform as follows (coordinates as in here). But these must be normalized by the image W and H. Coursat.ai YOLOv 5 fine tune on SF data Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai DETR fine tune on SF data Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai DETR fine tune on SF data Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai DETR fine tune on SF data Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai DETR fine tune on SF data Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Serving Scenarios Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai What is Serving? Copyright© 2022 by Coursat.ai. All rights reserved. Endpoints: /predict Coursat.ai Why Serving? • Scalability: millions of users, and millions of nodes (clusters) that grow dynamically without hastle. • Cost: can’t afford GPU per device • Latency: need fast serving pipeline Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Qualities of Production-Level Serving System • High availability Imagine how ridiculous the situation would be if a major website like Amazon were only 99.9% available, losing millions in user revenue during the eight-plus hours of downtime. Five 9 s is considered the holy grail. Anything less than three 9 s is typically unsuitable for a high-quality production system. Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Qualities of Production-Level Serving System • Scalability and load balancing Different peak-times (Netflix: Evening and Night). Cannot plan on the max. or one size fits all resources. Resources allocation has to be dynamic. Scale up with high traffic, down with low traffic. Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Qualities of Production-Level Serving System • Low latency Amazon published a study in 2008 in which it found that every 100 ms increase in latency in its retail website resulted in a 1% loss of profit. A onesecond delay in loading the website caused a whopping $1.6 billion in lost revenue! Google found that a 500 ms latency on mobile websites resulted in a traffic drop of 20%. In other words, a 20% decrease in the opportunity-to-serve advertisements. And this does not affect only industry giants. If a web page takes longer than three seconds to load on a mobile phone, 53% of users abandon it (according to a 2017 study by Google). It’s clear that time is money. Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Qualities of Production-Level Serving System • Geographic availability The distance between New York and Sydney is nearly 10,000 miles (16,000 km). The speed of light in a vacuum is roughly 186,282 miles per second (300,000 km per second). Silica glass (used in fiber-optic cables) decreases the speed of light by a factor of roughly 30% down to 130,487 miles per second (210,000 km per second). On a piece of fiber-optic running in a straight line between these two cities, the roundtrip travel time alone for a single request is nearly 152 ms. Services that expect to be used throughout the world must be strategically located to minimize latency for the users in those regions. Additionally, resources can be dynamically scaled up or down depending on local traffic, thus giving more granular control. Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Qualities of Production-Level Serving System • Failure handling • Monitoring • Model Versioning: to handle data drift, we need to continuously deploy re-trained models. Serving must be able to handle those versions seamlessly • A/B testing: we might need to deploy more than one version, for certain traffic groups. Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Serving scenarios landscape Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai How to choose? Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Hosted (BYOS) or Managed (Cloud ML)? • BYOS: Bring Your Own System • QPS: Queries per second In summary, the cost savings and performance benefits of orchestrating our own cloud machine environment kicks in big time when working on large QPS scenarios. Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Flask Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Basic flask app Copyright© 2022 by Coursat.ai. All rights reserved. Create app endpoint Send GET request Coursat.ai Passing params Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Image classification using torchvision Copyright© 2022 by Coursat.ai. All rights reserved. Notice we used POST here as we pass file Coursat.ai Custom model with Keras • Notice curl to send POST request • Same method is used with custom model Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Pros of Using Flask Flask provides some advantages, namely: • Quick to set up and to prototype • Fast development cycle • Lightweight on resources • Broad appeal within the Python community Cons of Using Flask At the same time, Flask might not be your best choice, for the following reasons: • Cannot scale; by default, it is not meant for production loads. Flask can serve only one request at one time • Does not handle model versioning out of the box • Does not support batching of requests out of the box Coursat.ai Django on EC 2 Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Django on EC 2 • Local/dev side • ML models side Already covered • Django framework side Local machine deployment localhost • Server side • Website settings • Remote server setup/Apache configuration • Remote instance (EC 2) choice Coursat.ai Coursat.ai Django project urls ● Why Django? ● Django tutorial here ● To start Django project ● We have an app called cv for still images ● Another one for videos cv_vid ● The main application route is cv/ ● Then we have 3 sub-urls that are mapped to the tasks Coursat.ai Backends 364 Coursat.ai To deploy as localhost 365 Coursat.ai AWS EC 2 instance launch Coursat.ai Create or set private key for SSH 367 Coursat.ai Set the inbound and outbound Ips allowed to access Coursat.ai Connect to the EC 2 instance with SSH Coursat.ai Configure our website Coursat.ai All details are here Coursat.ai TFServing Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai TFServing vs. Simple Flask • Tensorflow Serving makes use of gRPC and Protobuf while a regular Flask web service uses REST and JSON. JSON relies on HTTP 1.1 while gRPC uses HTTP/2 (there are important differences). In addition, Protobuf is a binary format used to serialize data and it is more efficient than JSON. • TensorFlow Serving can batch requests to the same model, which uses hardware (e.g. GPUs) more appropriate. • TensorFlow Serving can manage model versioning: json_response = requests.post(' 1/models/fashion_mod el:predict', data=data, headers=headers) Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Example in colab • Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Build model Copyright© 2022 by Coursat.ai. All rights reserved. Fashion mnist native example Coursat.ai Save model Copyright© 2022 by Coursat.ai. All rights reserved. Fashion mnist native example Coursat.ai Servable endpoint • SignatureDef = servable endpoint name: predict Copyright© 2022 by Coursat.ai. All rights reserved. Fashion mnist native example Coursat.ai Serve model • Install and run TFServing native: • Model_name will be used later to call the endpoint in the request (fashion_model:predict) Copyright© 2022 by Coursat.ai. All rights reserved. Fashion mnist native example Coursat.ai Send request Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Docker (Optional) Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai What is docker? • A docker is like a VM, but on a smaller scale, like a python env. But it has system wide installations beyond just python packages. • It’s like python venv with environment requirements.txt installations. But for system wide packages not only python (pip) • It contains an environment of software installations, that maps some native system mounted folders, ports,…etc. • A docker image is like the ISO OS image. It is built from docker file. • A docker file is like a makefile, with instructions to build and include certain libraries. • Once the image is built, you can instantiate it with docker run, which instantiates a docker container. • You can run any entry point while in the container (like /bash cmd). • Now it’s running as a server. • You can save and add any libraries to the running image using commit. Copyright© 2022 by Coursat.ai. All rights reserved. nvidia-docker file Coursat.ai Why docker? • Docker is very useful tool for DL in general. • You usually need a lot of installations to get a project up and running. • Some broken, or outdated packages, might make the installation a hassle, and non-reproducable. • To avoid the hassle, you can create a docker image, and run it every time Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Build docker file # cd to docker folder that contains the docker file sudo docker build -t [image_name] -f ./Dockerfile . Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Useful docker commands # to list all docker images on the machine: sudo docker images # to create a container from an image: //openning an image by defualt sudo docker run -it --name [new container name] [docker image name] /bin/bash Notice how the last command in the run is the one that the docker executes. /bin/bash means it will open a terminal like a remote machine or VM. # to get the running containers: sudo docker ps –a # to stop running container: sudo docker stop [container name or ID] # to start stopped container: sudo docker start -ai [container name or ID] # to save the changes made on the container to an existing or new image sudo docker commit [container id] [new or existing image name] Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Example: Jupyter in docker Copyright© 2022 by Coursat.ai. All rights reserved. # start a container command line /bin/bash sudo docker run --name my-docker -it -p 443:8888 [image_name] /bin/bash #the -p flag used to map the 8888 port to 443. This allow us to run notebook and connect to it from outside the docker on port 443 Then inside the docker : jupyter notebook --allow-root --port-retries=0 --port=8888 --no- browser --ip=0.0.0.0 #now you can open notebook on Coursat.ai TFServing + Docker Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Why TFServing + Docker? • Fun fact, TF serving example of official tensorflow on colab is broken! • tensorflow_model_server tool is build with old GLIBC package • So even for google, it’s hard to maintain system wide consistent packages (like python venv) Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Example •Notice that, after this command returns, the server is not down. It's still up. You can verify by running: sudo docker ps -a, or just call pass the request again and you will get predictions: curl -d '{"instances": [1.0, 2.0, 5.0]}’ \ -X POST 1/models/half_plus_two: predict •This is equivalent to running native: nohup tensorflow_model_server \ --rest_api_port=8501 \ --model_name=fashion_model \ --model_base_path="${MODEL_DIR}" >server.log 2>&1 • nohup = run in background even if the terminal is stopped Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Fashion mnist example with local docker • Train the model, and save: Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Serve the model • Notice another way of mapping the model path in the system to the docker using –mount type=bind, source=…, target=… • This is the same as –v source:target Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Query the model Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai ONNX Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai What is ONNX? • Open Neural Network Exchange • Open format built to represent machine learning models. • ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers. Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai Why ONNX? Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai How to use ONNX? Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai TensorFlow to ONNX conversion Copyright© 2022 by Coursat.ai. All rights reserved. Tensorflow-onnx tool ONNX supports any model fromat in TensorFlow, but SavedModel is preferred as it has all the graph connectivity information along with the weights Coursat.ai TensorFlow to ONNX conversion Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai TensorFlow to ONNX conversion Copyright© 2022 by Coursat.ai. All rights reserved. ONNXRuntime Coursat.ai Pytorch to ONNX conversion Copyright© 2022 by Coursat.ai. All rights reserved. ONNX Coursat.ai Pytorch to ONNX conversion Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai MLOps Coursat.ai Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai ML project steps 405 Coursat.ai ML Project lifecycle Coursat.ai Model drift ● Data drift P(X) changes ● Upstream data or features drift X Changes ● Concept drift or Label driftP(Y) changes ● How to detect? ○ Monitor! ■ Compare metrics like F 1 on both training and actual data ■ In case of big drift, this trigger model analysis e 069 c 660 d 37 a 18 c 17207 c 29/621697400190742156 fe 2 c 9 a_0*9 GoJLJSLjHQbs_dU.png e 069 c 660 d 37 a 18 c 17207 c 29/62101 c 5 a 724156 ea 7 a 6 c 228 c_DataDrift.jpeg Coursat.ai Where is ML development in production? Hidden Technical Debt in Machine Learning Systems Coursat.ai MLOps Cycle 409 Coursat.ai References • Practical Deep Learning for Cloud, Mobile, and Edge: Real-World AI & Computer-Vision Projects Using Python, Keras & TensorFlow 1 st Edition Copyright© 2022 by Coursat.ai. All rights reserved. Coursat.ai References A Survey of Model Compression and Acceleration for Deep Neural Networks Distilling the Knowledge in a Neural Network MODEL COMPRESSION VIA DISTILLATION AND QUANTIZATION RETHINKING THE VALUE OF NETWORK PRUNING M. Courbariaux and Y. Bengio, “Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1,” CoRR, vol. abs/1602.02830, 2016. M. Rastegari, V. Ordonez, J. Redmon, and A. Farhadi, “Xnor-net: Imagenet classification using binary convolutional neural networks,” in ECCV, 2016 C. Szegedy, S. Ioffe, and V. Vanhoucke, “Inception-v 4, inceptionresnet and the impact of residual connections on learning.” CoRR, vol. abs/1602.07261, 2016. B. Wu, F. N. Iandola, P. H. Jin, and K. Keutzer, “Squeezedet: Unified, small, low power fully convolutional neural networks for real-time object detection for autonomous driving,” CoRR, vol. abs/1612.01051, 2016. F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and K. Keutzer. Squeezenet: Alexnet-level accuracy with 50 x fewer parameters and 0.5 mb model size. arXiv preprint arXiv:1602.07360, 2016. Coursat.ai References J. Ba and R. Caruana, “Do deep nets really need to be deep?” in Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada, 2014, pp. 2654–2662. S. Zagoruyko and N. Komodakis, “Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer,” CoRR, vol. abs/1612.03928, 2016. A. Almahairi, N. Ballas, T. Cooijmans, Y. Zheng, H. Larochelle, and A. C. Courville, “Dynamic capacity networks,” in Proceedings of the 33 nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, 2016, pp. 2549–2558. N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean, “Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,” 2017. D. Wu, L. Pigou, P. Kindermans, N. D. Le, L. Shao, J. Dambre, and J. Odobez, “Deep dynamic neural networks for multimodal gesture segmentation and recognition,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 38, no. 8, pp. 1583–1597, 2016. Xundong Wu, Yong Wu, and Yong Zhao. High performance binarized neural networks trained on the imagenet classification task. CoRR, abs/1604.03058, 2016 b. URL abs/1604.03058. Coursat.ai References Song Han, Huizi Mao, andWilliam J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. ICLR, 2016 b. Hengyuan Hu, Rui Peng, Yu-Wing Tai, and Chi-Keung Tang. Network trimming: A data-driven neuron pruning approach towards efficient deep architectures. arXiv preprint arXiv:1607.03250, 2016. ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices F. Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv preprint arXiv:1610.02357, 2016. K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016. 1, 5 A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko,W.Wang, T. Weyand, M. Andreetto, and H. Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017. G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In CVPR, 2017. W. Chen, J. Wilson, S. Tyree, K. Weinberger, and Y. Chen. Compressing neural networks with the hashing trick. In ICML, pages 2285–2294, 2015 I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio. Binarized neural networks. In NIPS, pages 4107– 4115, 2016. Coursat.ai References B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le. Learning transferable architectures for scalable image recognition. arXiv preprint arXiv:1707.07012, 2017. MobileNetV 2: Inverted Residuals and Linear Bottlenecks DeepSZ: A Novel Framework to Compress Deep Neural Networks by Using Error-Bounded Lossy Compression Deep Neural Network Compression for Image Classification and Object Detection Searching for MobileNetV 3 EfficientDet: Scalable and Efficient Object Detection B. Zoph and Q. V. Le. Neural architecture search with reinforcement learning. In International Conference on Learning Representations, 2017. Coursat.ai References - Polino, A., Pascanu, R. and Alistarh, D., 2018. Model compression via distillation and quantization. arXiv preprint arXiv:1802.05668. - - A seminar report on Model Compression, submitted by Markus Beuckelmann, as part of the Advanced Machine Learning Seminar (SS 2016), - - - - - - 7 - HV 8 W 6 jfx 7 - ea 0425 d - - - - - Coursat.ai References - - - - - - - - - Coursat.ai References • • Practical Deep Learning for Cloud, Mobile, and Edge, Coursat.ai Conclusion ● Client/Device side deployment scenarios ● Edge deployment requirements and constraints ● Model compression techniques ● Optimized architectures and special conv types ● TFLite (+Pi, +Mobile) ● TFJS ● Black box vs. Whitebox models ● TFHub, TF-API, Scratch: Yolov 5 and DETR ● Model serving qualities ● Model serving landscape ● Flask, Django EC 2, TFSeving (+Docker) ● ONNX ● MLOps Coursat.ai Coursat.ai Thank you Copyright© 2022 by Coursat.ai. All rights reserved.